{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.getcwd()\n",
    "os.chdir(\"C:\\\\Users\\\\DELL\\\\Desktop\\\\AnomalyDetectionChallenge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from statistics import mean, stdev\n",
    "from math import sqrt\n",
    "\n",
    "## if normal is stationary , anomaly is non-stationary, then anomaly! vice versia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data11 = pd.read_csv(\"hexacopter-hil-fifo-ls-01.kev.csv\")\n",
    "data12 = pd.read_csv(\"hexacopter-hil-fifo-ls-02.kev.csv\")\n",
    "data13 = pd.read_csv(\"hexacopter-hil-fifo-ls-sporadic.kev.csv\")\n",
    "data14 = pd.read_csv(\"hexacopter-hil-full-while.kev.csv\")\n",
    "data15 = pd.read_csv(\"hexacopter-hil-half-while.kev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def:\n",
    "def get_commonkey():\n",
    "    \n",
    "    setlist=[]  # take the common key accross all key levels(ONLY training)\n",
    "    for i in range(1,11): \n",
    "        data=eval('data{}'.format(i))\n",
    "        data[\"key\"] = data[\"class\"]+data[\"event\"]\n",
    "        setlist=setlist+[set(data[\"key\"])]\n",
    "\n",
    "    common_key=setlist[0]\n",
    "    for i in range(1,len(setlist)):\n",
    "        common_key=common_key&setlist[i]   # common_key get, length 83 key level across all 10 training files!\n",
    "    return common_key\n",
    "\n",
    "def gen_model_df(dataframe):\n",
    "    newdata = []\n",
    "    dataframe[\"key\"] = dataframe[\"class\"] + dataframe[\"event\"]\n",
    "    dataframe[\"numKey\"] = dataframe[\"key\"].apply(lambda x: full_keyset.index(x) if x in full_keyset else -1)  \n",
    "    dataframe = dataframe[dataframe.numKey != -1]\n",
    "    dataframe[\"interval\"] = dataframe[\"time\"].diff()\n",
    "    dataframe = dataframe[dataframe.interval != 0]    # delete events that happen at same time(0.6% total records), current no better method!\n",
    "    dataframe.index = pd.RangeIndex(len(dataframe.index))\n",
    "    data_temp=dataframe[[\"key\",\"numKey\",\"interval\"]]\n",
    "    return data_temp\n",
    "\n",
    "\n",
    "# def gen_concat_df(d1,d2):\n",
    "#     df_0 = pd.concat([d1,d2])\n",
    "#     return df_0\n",
    "\n",
    "\n",
    "def interval_matrix(transitions,interval):  # return transition Matrix and the Matrix of events average time interval\n",
    "    \n",
    "    n = 1+ max(transitions)  # number of states\n",
    "    M = [[0]*n for _ in range(n)] # transition matrix\n",
    "    N = [[0]*n for _ in range(n)] # average time matrix\n",
    "    X = [[0]*n for _ in range(n)] # standard deviation matrix\n",
    "    u = 0\n",
    "    for (i,j) in zip(transitions,transitions[1:]):\n",
    "        u += 1\n",
    "        M[i][j] += 1\n",
    "        N[i][j] += interval[u]\n",
    "        avg_local = N[i][j]/M[i][j]\n",
    "        absdis = interval[u]-avg_local\n",
    "        sdv_local = sqrt(absdis*absdis/(M[i][j]))\n",
    "        X[i][j] = sdv_local\n",
    "    \n",
    "    a = np.array(N)\n",
    "    b = np.array(M)\n",
    "    N = np.divide(a, b, out = np.zeros_like(a), where = b!= 0) # take average time interval of each event sequence\n",
    "        \n",
    "    #now convert to probabilities:\n",
    "    for row in M:\n",
    "        s = sum(row)\n",
    "        if s > 0:\n",
    "            row[:] = [f/s for f in row]\n",
    "    M = np.array(M)\n",
    "    X = np.array(X)\n",
    "    \n",
    "    return M,N,X\n",
    "\n",
    "\n",
    "def split_testing(data,N):  # split data onto many parts, return a list of data  \n",
    "    datas=np.array_split(data, N)\n",
    "    return datas\n",
    "\n",
    "\n",
    "def run_model(model_input):\n",
    "    transition_matrix, averagetime_matrix,std_matrix = interval_matrix(model_input[\"numKey\"],model_input[\"interval\"])\n",
    "    return transition_matrix, averagetime_matrix,std_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training: \n",
    "data1 = pd.read_csv(\"hexacopter-hil-clean-01.kev.csv\")\n",
    "data2 = pd.read_csv(\"hexacopter-hil-clean-02.kev.csv\")\n",
    "data3 = pd.read_csv(\"hexacopter-hil-clean-03.kev.csv\")\n",
    "data4 = pd.read_csv(\"hexacopter-hil-clean-04.kev.csv\")\n",
    "data5 = pd.read_csv(\"hexacopter-hil-clean-05.kev.csv\")\n",
    "data6 = pd.read_csv(\"hexacopter-hil-clean-06.kev.csv\")\n",
    "data7 = pd.read_csv(\"hexacopter-hil-clean-07.kev.csv\")\n",
    "data8 = pd.read_csv(\"hexacopter-hil-clean-08.kev.csv\")\n",
    "data9 = pd.read_csv(\"hexacopter-hil-clean-09.kev.csv\")\n",
    "data10 = pd.read_csv(\"hexacopter-hil-clean-10.kev.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "full_keyset = get_commonkey()\n",
    "full_keyset = list(full_keyset)\n",
    "length = len(full_keyset)\n",
    "\n",
    "\n",
    "# def train_model():\n",
    "\n",
    "result = []\n",
    "avg_time = []\n",
    "w_time = []\n",
    "\n",
    "for i in range(1,11):  # dataset level training, 1-10 clean datasets\n",
    "    \n",
    "    df_newdata=eval('data{}'.format(i))\n",
    "    \n",
    "    split_df= split_testing(df_newdata,)\n",
    "    \n",
    "    for j in range(len(split_df)):\n",
    "        \n",
    "        input_df = split_df[j]\n",
    "        df_model = gen_model_df(input_df)\n",
    "        tm,am,sm = run_model(df_model)\n",
    "        wti = tm*am\n",
    "#         avg_time += [np.sum(am)/np.count_nonzero(am)]\n",
    "        w_time += [np.sum(wti)/np.count_nonzero(wti)]\n",
    "        \n",
    "\n",
    "np.mean(w_time),np.std(w_time),np.max(w_time),np.min(w_time),np.ptp(w_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71.06044297900065,\n",
       " 5.422607572961724,\n",
       " 84.70784362422121,\n",
       " 53.46321571035906,\n",
       " 31.244627913862153,\n",
       " 500)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(w_time),np.std(w_time),np.max(w_time),np.min(w_time),np.ptp(w_time),len(w_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly detected! Location file:11,fraction:0\n",
      "anomaly detected! Location file:12,fraction:0\n",
      "anomaly detected! Location file:13,fraction:0\n",
      "anomaly detected! Location file:14,fraction:0\n",
      "anomaly detected! Location file:15,fraction:0\n"
     ]
    }
   ],
   "source": [
    "# def train model:\n",
    "\n",
    "avg_time_t = []\n",
    "w_time_t = []\n",
    "anomaly_record = []\n",
    "upper = np.mean(w_time)+3*np.std(w_time)\n",
    "lower = np.mean(w_time)-3*np.std(w_time)\n",
    "\n",
    "for i in range(11,16):  # dataset level training, 1-10 clean datasets\n",
    "    \n",
    "    df_newdata=eval('data{}'.format(i))\n",
    "    \n",
    "    split_df= split_testing(df_newdata,50)\n",
    "    \n",
    "    for j in range(len(split_df)):\n",
    "        \n",
    "        input_df = split_df[j]\n",
    "        df_model = gen_model_df(input_df)\n",
    "        tm,am,sm = run_model(df_model)\n",
    "        wti_t = tm*am\n",
    "        avg_wti_t = np.sum(wti)/np.count_nonzero(wti_t)\n",
    "    \n",
    "        w_time_t += [avg_wti_t]\n",
    "        \n",
    "        if avg_wti_t > upper or avg_wti_t < lower:\n",
    "            anomaly_record += [(i,j)] \n",
    "        \n",
    "        if len(anomaly_record)/len(w_time_t) > 0.05:\n",
    "            print(\"anomaly detected! Location file:{0},fraction:{1}\".format(i,j)) \n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54.43794535374846,\n",
       " 6.324280632734518,\n",
       " 79.23131479430678,\n",
       " 41.91478037109533,\n",
       " 37.31653442321145,\n",
       " {41.91478037109533,\n",
       "  43.0683981794741,\n",
       "  43.2668700604855,\n",
       "  43.46717964409886,\n",
       "  43.56803156902717,\n",
       "  43.66935257267607,\n",
       "  43.77114593531634,\n",
       "  43.976163012296745,\n",
       "  44.497207597750496,\n",
       "  44.60290167755513,\n",
       "  44.709099062501686,\n",
       "  44.81580335620694,\n",
       "  44.923018196772034,\n",
       "  45.03074725719595,\n",
       "  45.24776290662822,\n",
       "  45.35705701992925,\n",
       "  45.46688040254409,\n",
       "  45.577236908375504,\n",
       "  45.91154426956164,\n",
       "  46.024072564339974,\n",
       "  46.36499162037212,\n",
       "  46.47975645111562,\n",
       "  46.595090834369,\n",
       "  46.827485302370846,\n",
       "  46.94455401562677,\n",
       "  47.06220953947546,\n",
       "  47.180456297112336,\n",
       "  47.29929875629902,\n",
       "  47.41874142992603,\n",
       "  47.53878887658407,\n",
       "  47.65944570114393,\n",
       "  47.780716555345315,\n",
       "  47.90260613839467,\n",
       "  48.025119197572145,\n",
       "  48.14826052884797,\n",
       "  48.27203497750825,\n",
       "  48.52150285852896,\n",
       "  48.647206233810124,\n",
       "  48.773562613638205,\n",
       "  48.90057709961122,\n",
       "  49.028254846607595,\n",
       "  49.15660106348353,\n",
       "  49.28562101378139,\n",
       "  49.415320016449236,\n",
       "  49.54570344657179,\n",
       "  49.676776736112984,\n",
       "  49.80854537467032,\n",
       "  50.342685271449625,\n",
       "  50.47801507056642,\n",
       "  50.61407441037927,\n",
       "  50.750869206082996,\n",
       "  51.026689147420406,\n",
       "  51.165726447549616,\n",
       "  51.446086592467694,\n",
       "  51.587421995194255,\n",
       "  52.01612633310446,\n",
       "  52.16061557291864,\n",
       "  52.45201565991818,\n",
       "  52.74668990519862,\n",
       "  52.895272130283686,\n",
       "  53.19496205736745,\n",
       "  53.34608410866679,\n",
       "  53.498067254275526,\n",
       "  53.80464643624845,\n",
       "  53.959257489226175,\n",
       "  54.27116071170725,\n",
       "  54.4284684239151,\n",
       "  54.58669071584509,\n",
       "  54.74583558673676,\n",
       "  54.90591112938804,\n",
       "  55.066925531527005,\n",
       "  55.228887077207965,\n",
       "  55.39180414823218,\n",
       "  55.55568522559381,\n",
       "  55.72053889095166,\n",
       "  55.88637382812711,\n",
       "  56.053198824628986,\n",
       "  56.22102277320572,\n",
       "  56.38985467342555,\n",
       "  56.55970363328527,\n",
       "  56.73057887084806,\n",
       "  56.90248971591124,\n",
       "  57.07544561170428,\n",
       "  57.24945611661801,\n",
       "  57.42453090596547,\n",
       "  57.600679773775184,\n",
       "  57.777912634617564,\n",
       "  57.95623952546515,\n",
       "  58.135670607587336,\n",
       "  58.316216168480466,\n",
       "  58.497886623833985,\n",
       "  58.680692519533466,\n",
       "  58.86464453370128,\n",
       "  59.04975347877581,\n",
       "  59.236030303629995,\n",
       "  59.42348609573009,\n",
       "  59.61213208333558,\n",
       "  59.80197963774111,\n",
       "  59.99304027556137,\n",
       "  60.18532566105996,\n",
       "  60.37884760852318,\n",
       "  60.57361808467971,\n",
       "  61.16554269137039,\n",
       "  61.36543008578663,\n",
       "  61.56662821721544,\n",
       "  61.76915002056154,\n",
       "  62.17821723924076,\n",
       "  62.38478938953724,\n",
       "  62.59273868750236,\n",
       "  62.802078950671266,\n",
       "  63.22498857323471,\n",
       "  63.87014151785955,\n",
       "  64.08812834897853,\n",
       "  64.30760824058461,\n",
       "  64.97516126730349,\n",
       "  65.2007694661483,\n",
       "  66.3527265238541,\n",
       "  66.58801988032167,\n",
       "  67.54612088579391,\n",
       "  67.78996969765599,\n",
       "  68.2829876590935,\n",
       "  68.78322932692568,\n",
       "  70.5933143092132,\n",
       "  71.67107483301797,\n",
       "  79.23131479430678})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(w_time_t),np.std(w_time_t),np.max(w_time_t),np.min(w_time_t),np.ptp(w_time_t),set(w_time_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 3), 2]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(2,3),(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "## initial data processing, newdata contain 15 files, 10 training + 5 testing\n",
    "\n",
    "setlist=[]  # take the common key accross all key levels(training+testing)\n",
    "for i in range(1,16): \n",
    "    data=eval('data{}'.format(i))\n",
    "    data[\"key\"] = data[\"class\"]+data[\"event\"]\n",
    "    setlist=setlist+[set(data[\"key\"])]\n",
    "\n",
    "common_key=setlist[0]\n",
    "for i in range(1,11):\n",
    "    common_key=common_key&setlist[i]   # common_key get, length 74 key level across all 15 files!\n",
    "                                \n",
    "\n",
    "newdata=[]\n",
    "full_key_set = list(common_key) \n",
    "for i in range(1,16): \n",
    "    data=eval('data{}'.format(i))\n",
    "    data[\"key\"] = data[\"class\"]+data[\"event\"]\n",
    "    data[\"numKey\"] = data[\"key\"].apply(lambda x: full_key_set.index(x) if x in full_key_set else -1)  # change string key to number key, unique to -1!\n",
    "    data = data[data.numKey != -1]  \n",
    "    data.sort_values(\"time\", axis = 0, ascending = True, inplace = True)  # 0.05% data timestamp NOT correct!\n",
    "    data[\"interval\"] = data[\"time\"].diff()\n",
    "    data = data[data.interval != 0]    # delete events that happen at same time(0.6% total records), current no better method!\n",
    "    data.index = pd.RangeIndex(len(data.index))\n",
    "    data_temp=data[[\"key\",\"numKey\",\"interval\"]]\n",
    "    newdata = newdata + [data_temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = []\n",
    "atm = []\n",
    "sdm = []\n",
    "\n",
    "for i in range(len(newdata)):\n",
    "    a,b,c = interval_matrix(newdata[i].numKey,newdata[i].interval)\n",
    "    \n",
    "    tm += [a]\n",
    "    atm += [b]\n",
    "    sdm += [c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505.02140864567656"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atm[1]\n",
    "\n",
    "tmi= []\n",
    "\n",
    "\n",
    "multi = []\n",
    "sd = []\n",
    "for i in range(len(atm)):\n",
    "    itm = np.linalg.det(atm[i])\n",
    "    multi += [itm]\n",
    "    tmi += [sum(sum(atm[i]))/np.count_nonzero(atm[i])]\n",
    "    sd += [sum(sum(sdm[i]))/(np.count_nonzero(sdm[i]))]\n",
    "    \n",
    "\n",
    "multi\n",
    "mean(tmi)\n",
    "# import matplotlib as plt\n",
    "\n",
    "# # % matplotlin\n",
    "# a= pd.DataFrame({\"avg\":tmi})\n",
    "# a.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 58,\n",
       " 60,\n",
       " 61,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst=data1[:50000]\n",
    "set(tst.numKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_matrix(transition): # reward matrix\n",
    "    reward = np.array(transition)\n",
    "    reward[reward != 0] = 1\n",
    "    reward[reward == 0] = -1\n",
    "    return reward\n",
    "\n",
    "\n",
    "\n",
    "rwd_matrix()## 实时概率矩阵\n",
    "\n",
    "def score(indicator, reward):   # return stability score\n",
    "    indicator = np.array(indicator)\n",
    "    reward = np.array(reward)\n",
    "    score = sum(sum(indicator*reward))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def generate_setlist(data):  # combine column \"class\" and \"event\"  into one column called \"key\"\n",
    "    \n",
    "#     setlist = []\n",
    "#     data[\"key\"] = data[\"class\"]+data[\"event\"]\n",
    "#     setlist += list(set(data[\"key\"]))\n",
    "#     return setlist\n",
    "    \n",
    "# def find_commonkey(data1,data2):  # get common key of two datasets--Finally no common key in the processing and analysis , only use common keys in the training dataset!!\n",
    "    \n",
    "    \n",
    "#     key1 = generate_setlist(data1)\n",
    "#     key2 = generate_setlist(data2)\n",
    "#     common_key = list(set(key1) & set(key2))\n",
    "#     return common_key\n",
    "\n",
    "def gen_concat_df(d1,d2):\n",
    "    df_0 = pd.concat([d1,d2])\n",
    "    return df_0\n",
    "\n",
    "\n",
    "def gen_model_df(dataframe):\n",
    "    newdata = []\n",
    "    dataframe[\"key\"] = dataframe[\"class\"] + dataframe[\"event\"]\n",
    "    dataframe[\"numKey\"] = dataframe[\"key\"].apply(lambda x: full_keyset.index(x) if x in full_keyset else -1)  \n",
    "    dataframe = dataframe[dataframe.numKey != -1]\n",
    "    dataframe[\"interval\"] = dataframe[\"time\"].diff()\n",
    "    dataframe = dataframe[dataframe.interval != 0]    # delete events that happen at same time(0.6% total records), current no better method!\n",
    "    data_temp=dataframe[[\"key\",\"numKey\",\"interval\"]]\n",
    "    return data_temp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def concat_df(data1,data2):\n",
    "    \n",
    "    newdata=[]\n",
    "    data0 = pd.concat([data1,data2])\n",
    "    data0[\"key\"] = data0[\"class\"] + data0[\"event\"]\n",
    "    data0[\"numKey\"] = data0[\"key\"].apply(lambda x: full_keyset.index(x) if x in full_keyset else -1)  \n",
    "    data0 = data0[data0.numKey != -1]\n",
    "    data0.sort_values(\"time\", axis = 0, ascending = True, inplace = True)\n",
    "    data0[\"interval\"] = data0[\"time\"].diff()\n",
    "    data0 = data0[data0.interval != 0]    # delete events that happen at same time(0.6% total records), current no better method!\n",
    "#     data0.index = pd.RangeIndex(len(data0.index))\n",
    "    data_temp=data0[[\"key\",\"numKey\",\"interval\"]]\n",
    "    return data_temp,data0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def interval_matrix(transitions,interval):  # return transition,avgtime,variance Matrix\n",
    "    \n",
    "    n = 1+ max(transitions)  # number of states\n",
    "    M = [[0]*n for _ in range(n)] # transition matrix\n",
    "    N = [[0]*n for _ in range(n)] # average time matrix\n",
    "    X = [[0]*n for _ in range(n)] # standard deviation matrix\n",
    "    u = 0\n",
    "\n",
    "    for (i,j) in zip(transitions,transitions[1:]):\n",
    "        u += 1\n",
    "        M[i][j] += 1\n",
    "        N[i][j] += interval[u]\n",
    "        avg_local = N[i][j]/M[i][j]\n",
    "        absdis = interval[u]-avg_local\n",
    "        sdv_local = sqrt(absdis*absdis/(M[i][j]))\n",
    "        X[i][j] = sdv_local\n",
    "    \n",
    "    a = np.array(N)\n",
    "    b = np.array(M)\n",
    "    N = np.divide(a, b, out = np.zeros_like(a), where = b!= 0) # take average time interval of each event sequence\n",
    "\n",
    "    for row in M:\n",
    "        s = sum(row)\n",
    "        if s > 0:\n",
    "            row[:] = [f/s for f in row]\n",
    "            \n",
    "    M = np.array(M)\n",
    "    X = np.array(X)\n",
    "    return M,N,X\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_concat_df(d1,d2):\n",
    "    df_0 = pd.concat([d1,d2])\n",
    "    return df_0\n",
    "\n",
    "\n",
    "def gen_model_df(dataframe):\n",
    "    newdata = []\n",
    "    dataframe[\"key\"] = dataframe[\"class\"] + dataframe[\"event\"]\n",
    "    dataframe[\"numKey\"] = dataframe[\"key\"].apply(lambda x: full_keyset.index(x) if x in full_keyset else -1)  \n",
    "    dataframe = dataframe[dataframe.numKey != -1]\n",
    "    dataframe[\"interval\"] = dataframe[\"time\"].diff()\n",
    "    dataframe = dataframe[dataframe.interval != 0]    # delete events that happen at same time(0.6% total records), current no better method!\n",
    "    data_temp=dataframe[[\"key\",\"numKey\",\"interval\"]]\n",
    "    return data_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>numKey</th>\n",
       "      <th>interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CONTROLBUFFER</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>PROCESSPROCCREATE_NAME</td>\n",
       "      <td>22</td>\n",
       "      <td>288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>THREADTHCREATE</td>\n",
       "      <td>26</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>THREADTHREADY</td>\n",
       "      <td>60</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>THREADTHCREATE</td>\n",
       "      <td>26</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>685778</td>\n",
       "      <td>COMMSND_PULSE_EXE</td>\n",
       "      <td>78</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>685779</td>\n",
       "      <td>THREADTHREADY</td>\n",
       "      <td>60</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>685780</td>\n",
       "      <td>COMMSND_PULSE_EXE</td>\n",
       "      <td>78</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>685781</td>\n",
       "      <td>COMMREC_PULSE</td>\n",
       "      <td>66</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>685782</td>\n",
       "      <td>KER_EXITMSG_RECEIVEV/14</td>\n",
       "      <td>59</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1357163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            key  numKey  interval\n",
       "0                 CONTROLBUFFER      25       NaN\n",
       "2        PROCESSPROCCREATE_NAME      22     288.0\n",
       "3                THREADTHCREATE      26     117.0\n",
       "4                 THREADTHREADY      60      30.0\n",
       "5                THREADTHCREATE      26      53.0\n",
       "...                         ...     ...       ...\n",
       "685778        COMMSND_PULSE_EXE      78      29.0\n",
       "685779            THREADTHREADY      60      27.0\n",
       "685780        COMMSND_PULSE_EXE      78      32.0\n",
       "685781            COMMREC_PULSE      66     150.0\n",
       "685782  KER_EXITMSG_RECEIVEV/14      59      39.0\n",
       "\n",
       "[1357163 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0 = gen_concat_df(data1,data2)\n",
    "gen_model_df(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_vector(numKey):\n",
    "    a = np.zeros(length)\n",
    "    a[numKey] = 1\n",
    "    return a\n",
    "\n",
    "vector_dictionary = {i:gen_vector(i) for i in range(length)}\n",
    "# k=vector_dictionary[1]\n",
    "# sum(k == gen_vector(1))\n",
    "\n",
    "def gen_vector_matrix(cc):   # create event matrix\n",
    "    matrix = np.stack(map(lambda x: vector_dictionary[x], cc.numKey))\n",
    "    matrix_T = matrix.T\n",
    "    return matrix_T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a=np.stack((vector_dictionary[0],vector_dictionary[1],vector_dictionary[2],vector_dictionary[3])).T\n",
    "# tm2.dot(a)\n",
    "\n",
    "\n",
    "cc0, datae = concat_df(data1, data2)\n",
    "\n",
    "tm2, am2, sm2 = run_model(cc0)\n",
    "\n",
    "\n",
    "cc1, datae = concat_df(datae, data3)\n",
    "\n",
    "tm3, am3, sm3 = run_model(cc1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cc15, dat15 = concat_df(datae, data15)\n",
    "tm15, am15, sm15 = run_model(cc15)\n",
    "\n",
    "cc14, dat14 = concat_df(datae, data14)\n",
    "tm14, am14, sm14 = run_model(cc14)\n",
    "\n",
    "cc13, dat13 = concat_df(datae, data13)\n",
    "tm13, am13, sm13 = run_model(cc13)\n",
    "\n",
    "cc12, dat12 = concat_df(datae, data12)\n",
    "tm12, am12, sm12 = run_model(cc12)\n",
    "\n",
    "cc11, dat11 = concat_df(datae, data11)\n",
    "tm11, am11, sm11 = run_model(cc11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'am' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-ef7105476c15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'am' is not defined"
     ]
    }
   ],
   "source": [
    "np.linalg.det(am)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0995617320288018e+76"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=am2-am4\n",
    "b=np.array([[1,0],[0,4]])-np.array([[0,0],[0,2]])\n",
    "c=np.array([[1,0],[0,4]])\n",
    "np.linalg.det(am4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n",
      "360\n",
      "422\n"
     ]
    }
   ],
   "source": [
    "kk1=np.stack(map(lambda x : vector_dictionary[x],cc0.numKey)).T\n",
    "\n",
    "# kk2=np.stack(map(lambda x : vector_dictionary[x],cc1.numKey)).T\n",
    "\n",
    "# kk3=np.stack(map(lambda x : vector_dictionary[x],cc2.numKey)).T\n",
    "\n",
    "a1=np.linalg.matrix_power(tm2,10)\n",
    "# a2=np.linalg.matrix_power(tm3,10)\n",
    "# a3=np.linalg.matrix_power(tm4,10)\n",
    "\n",
    "\n",
    "b1 = a1.dot(kk1)\n",
    "# b2 = a2.dot(kk2)\n",
    "# b3 = a3.dot(kk3)\n",
    "\n",
    "r1 = np.argmax(b1,axis = 0)\n",
    "# r2 = np.argmax(b2,axis = 0)\n",
    "# r3 = np.argmax(b3,axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(sum(r2[500000:600000]==cc1.numKey[500010:600010]))\n",
    "\n",
    "# print(sum(r3[500000:600000]==cc2.numKey[500010:600010]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0.        ,     0.        ,     0.        , ...,\n",
       "            0.        ,     0.        ,   101.88235294],\n",
       "       [   47.5       ,     0.        ,   365.75373134, ...,\n",
       "          186.73484848,   362.65384615, 23577.6197411 ],\n",
       "       [    0.        ,     0.        ,     0.        , ...,\n",
       "            0.        ,     0.        ,    83.43478261],\n",
       "       ...,\n",
       "       [    0.        ,     0.        ,     0.        , ...,\n",
       "            0.        ,     0.        ,   174.38655462],\n",
       "       [    0.        ,     0.        ,     0.        , ...,\n",
       "            0.        ,     0.        ,    83.81818182],\n",
       "       [    0.        ,     0.        ,     0.        , ...,\n",
       "            0.        ,     0.        ,     0.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=np.linalg.matrix_power(tm2,200000)\n",
    "a2=a1.dot(kk)\n",
    "# np.amax(a,axis=0)[1:150]\n",
    "xz=np.argmax(a2,axis=0)\n",
    "\n",
    "b1=np.linalg.matrix_power(tm4,200000)\n",
    "b2=b1.dot(kk)\n",
    "# np.amax(a,axis=0)[1:150]\n",
    "xz=np.argmax(a2,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2719"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(xz[:100000]==cc0.numKey[100000:200000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10     76\n",
       "11     55\n",
       "12     76\n",
       "13     55\n",
       "14     76\n",
       "       ..\n",
       "205     6\n",
       "206    79\n",
       "207    36\n",
       "208    21\n",
       "209    15\n",
       "Name: numKey, Length: 200, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc0.numKey[10:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 5],\n",
       "       [0, 4]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_power(np.array([[3,1],[0,2]]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test=split_testing(data1,200)\n",
    "# \n",
    "# cc0,data0 = concat_df(test[0],test[1])\n",
    "\n",
    "# tm1,am1,sm1 = run_model(cc0)\n",
    "\n",
    "# 用cc0 创造产生matrix的df， 用data0 来拼接下一个df\n",
    "# cc0, data0 = concat_df(data0, test[2])\n",
    "\n",
    "# cc0, data0 = concat_df(data1, data2)\n",
    "\n",
    "# tm2, am2, sm2 = run_model(cc0)\n",
    "\n",
    "\n",
    "cc1, data0 = concat_df(data0, data3)\n",
    "\n",
    "tm3, am3, sm3 = run_model(cc1)\n",
    "\n",
    "\n",
    "cc2, data0 = concat_df(data0, data15)\n",
    "\n",
    "\n",
    "tm4, am4, sm4 = run_model(cc2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1357157"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cc0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2=am4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "737.0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1[k1 == 0] = 0\n",
    "k1[k1 != 0 ] = 1\n",
    "k1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "737.0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k2[k1 == 0] = 0\n",
    "k2[k1 != 0 ] = 1\n",
    "k2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{1,2,3}+{2,4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=np.array(tm[1])*np.array(prob[1])\n",
    "lst=[]\n",
    "for i in range(len(newdata)):\n",
    "    lst = lst+[sum(sum(tm[i]))]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.ylim(240000,350000) \n",
    "plt.xlim(0,17)\n",
    "\n",
    "plt.plot(range(1,16),lst)\n",
    "\n",
    "from statistics import mean, stdev\n",
    "\n",
    "stdev(lst[:10]),mean(lst[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multipl=[]\n",
    "for i in range(15):\n",
    "    a=(lst[i]-mean(lst[:10]))/stdev(lst[:10])\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([3])&set([2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "t=[2,1,0,2,1,2,0,2,2]\n",
    "va=[None,100,0,2,1,2,0,2,100]\n",
    "\n",
    "u = 0\n",
    "v = 0\n",
    "\n",
    "n = 1+ max(t)  # number of states\n",
    "M = [[0]*n for _ in range(n)] # \n",
    "N = [[0]*n for _ in range(n)] #\n",
    "X = [[0]*n for _ in range(n)]\n",
    "\n",
    "for (i,j) in zip(t,t[1:]):\n",
    "    u += 1\n",
    "    M[i][j] += 1\n",
    "    N[i][j] += va[u]\n",
    "    avg_local = N[i][j]/M[i][j]\n",
    "    sdv_local = sqrt((va[u]-avg_local)**2/(M[i][j]))\n",
    "    X[i][j] = sdv_local\n",
    "\n",
    "print(M)\n",
    "print(N)   \n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "foo = np.array(X)\n",
    "foo[foo != 0] = 1\n",
    "foo[foo == 0] = -1\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_testing(data,N):  # split data onto many parts, return a list of data\n",
    "        \n",
    "    datas=np.array_split(data, N)\n",
    "    return datas\n",
    "\n",
    "def generate_setlist(data):  # combine column \"class\" and \"event\"  into one column called \"key\"\n",
    "    \n",
    "    setlist = []\n",
    "    data[\"key\"] = data[\"class\"]+data[\"event\"]\n",
    "    setlist += list(set(data[\"key\"]))\n",
    "    return setlist\n",
    "    \n",
    "def find_commonkey(data1,data2, testing = False):  # get common key of two datasets\n",
    "    \n",
    "    key1 = generate_setlist(data1)\n",
    "    key2 = generate_setlist(data2)\n",
    "    common_key = list(set(key1) | set(key2))\n",
    "    return common_key\n",
    "\n",
    "def concat_df(data1,data2,testing = False):\n",
    "    \n",
    "    newdata=[]\n",
    "    full_keyset = find_commonkey(data1,data2)\n",
    "    data0 = pd.concat([data1,data2])\n",
    "    data0[\"key\"] = data0[\"class\"] + data0[\"event\"]\n",
    "    data0[\"numKey\"] = data0[\"key\"].apply(lambda x: full_keyset.index(x) if x in full_keyset else -1)  \n",
    "    data0 = data0[data0.numKey != -1]\n",
    "    data0.sort_values(\"time\", axis = 0, ascending = True, inplace = True)\n",
    "    data0[\"interval\"] = data0[\"time\"].diff()\n",
    "    data0 = data0[data0.interval != 0]    # delete events that happen at same time(0.6% total records), current no better method!\n",
    "    data0.index = pd.RangeIndex(len(data0.index))\n",
    "    data_temp=data0[[\"key\",\"numKey\",\"interval\"]]\n",
    "    return data_temp,data0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def interval_matrix(transitions,interval):  # return transition,avgtime,variance Matrix\n",
    "    \n",
    "    n = 1+ max(transitions)  # number of states\n",
    "    M = [[0]*n for _ in range(n)] # transition matrix\n",
    "    N = [[0]*n for _ in range(n)] # average time matrix\n",
    "    X = [[0]*n for _ in range(n)] # standard deviation matrix\n",
    "    u = 0\n",
    "\n",
    "    for (i,j) in zip(transitions,transitions[1:]):\n",
    "        u += 1\n",
    "        M[i][j] += 1\n",
    "        N[i][j] += interval[u]\n",
    "        avg_local = N[i][j]/M[i][j]\n",
    "        absdis = interval[u]-avg_local\n",
    "        sdv_local = sqrt(absdis*absdis/(M[i][j]))\n",
    "        X[i][j] = sdv_local\n",
    "    \n",
    "    a = np.array(N)\n",
    "    b = np.array(M)\n",
    "    N = np.divide(a, b, out = np.zeros_like(a), where = b!= 0) # take average time interval of each event sequence\n",
    "\n",
    "    for row in M:\n",
    "        s = sum(row)\n",
    "        if s > 0:\n",
    "            row[:] = [f/s for f in row]\n",
    "            \n",
    "    M = np.array(M)\n",
    "    X = np.array(X)\n",
    "    return M,N,X\n",
    "\n",
    "\n",
    "def run_model(data):\n",
    "    \n",
    "    transition_matrix, averagetime_matrix,std_matrix = interval_matrix(data[\"numKey\"],data[\"interval\"])\n",
    "    return transition_matrix, averagetime_matrix,std_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_commonkey(data1,data2, testing = False):  # get common key of two datasets\n",
    "    \n",
    "    if testing == True:\n",
    "        key = generate_setlist(data1)\n",
    "        common_key = list(set(key))\n",
    "        print(\"testing True\")\n",
    "    else:\n",
    "        key1 = generate_setlist(data1)\n",
    "        key2 = generate_setlist(data2)\n",
    "        common_key = list(set(key1) | set(key2))\n",
    "        print(\"000000\")\n",
    "        \n",
    "    return common_key\n",
    "\n",
    "def concat_df(data1,data2,testing = False):\n",
    "    \n",
    "#     newdata=[]\n",
    "    if testing == True:\n",
    "        full_keyset = find_commonkey(data1,data2,testing = True)\n",
    "    else:\n",
    "        full_keyset = find_commonkey(data1,data2)\n",
    "    \n",
    "    return full_keyset \n",
    "\n",
    "#     data0 = pd.concat([data1,data2])\n",
    "#     data0[\"key\"] = data0[\"class\"] + data0[\"event\"]\n",
    "#     data0[\"numKey\"] = data0[\"key\"].apply(lambda x: full_keyset.index(x) if x in full_keyset else -1)  \n",
    "#     data0 = data0[data0.numKey != -1]\n",
    "#     data0.sort_values(\"time\", axis = 0, ascending = True, inplace = True)\n",
    "#     data0[\"interval\"] = data0[\"time\"].diff()\n",
    "#     data0 = data0[data0.interval != 0]    # delete events that happen at same time(0.6% total records), current no better method!\n",
    "#     data0.index = pd.RangeIndex(len(data0.index))\n",
    "#     data_temp=data0[[\"key\",\"numKey\",\"interval\"]]\n",
    "#     return data_temp,data0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 'PROCESSPROCTHREAD_NAME'),\n",
       " (1, 'INT_ENTR0x00000044'),\n",
       " (2, 'COMMREPLY_MESSAGE'),\n",
       " (3, 'CONTROLTIME'),\n",
       " (4, 'USREVENTEVENT-2'),\n",
       " (5, 'KER_CALLMSG_DELIVER_EVENT/21'),\n",
       " (6, 'COMMREC_PULSE'),\n",
       " (7, 'INT_HANDLER_EXIT0x00000049'),\n",
       " (8, 'INT_HANDLER_ENTR0x0000002e'),\n",
       " (9, 'INT_EXIT0x00000049'),\n",
       " (10, 'THREADTHCONDVAR'),\n",
       " (11, 'THREADTHREADY'),\n",
       " (12, 'THREADTHSIGWAITINFO'),\n",
       " (13, 'KER_CALLTIMER_TIMEOUT/75'),\n",
       " (14, 'KER_EXITMSG_CURRENT/10'),\n",
       " (15, 'COMMSND_PULSE_EXE'),\n",
       " (16, 'KER_EXITMSG_REPLYV/15'),\n",
       " (17, 'KER_CALLCONNECT_CLIENT_INFO/42'),\n",
       " (18, 'KER_CALLSIGNAL_WAITINFO/32'),\n",
       " (19, 'KER_EXITMSG_INFO/19'),\n",
       " (20, 'USREVENTEVENT-0'),\n",
       " (21, 'INT_HANDLER_ENTR0x00000029'),\n",
       " (22, 'KER_CALLMSG_ERROR/13'),\n",
       " (23, 'KER_EXITMSG_SENDV/11'),\n",
       " (24, 'KER_CALLMSG_SENDV/11'),\n",
       " (25, 'KER_CALLMSG_CURRENT/10'),\n",
       " (26, 'KER_CALLCONNECT_DETACH/40'),\n",
       " (27, 'INT_EXIT0x00000044'),\n",
       " (28, 'USREVENTEVENT-3'),\n",
       " (29, 'KER_CALLMSG_SENDVNC/12'),\n",
       " (30, 'INT_HANDLER_ENTR0x00000044'),\n",
       " (31, 'KER_CALLSYNC_CONDVAR_SIGNAL/83'),\n",
       " (32, 'THREADTHWAITPAGE'),\n",
       " (33, 'KER_EXITSYNC_CONDVAR_WAIT/82'),\n",
       " (34, 'KER_CALLMSG_RECEIVEV/14'),\n",
       " (35, 'KER_EXITTRACE_EVENT/01'),\n",
       " (36, 'INT_ENTR0x00000029'),\n",
       " (37, 'SYSTEMPATHMGR_OPEN'),\n",
       " (38, 'THREADTHNANOSLEEP'),\n",
       " (39, 'CONTROLBUFFER'),\n",
       " (40, 'INT_HANDLER_ENTR0x0000002d'),\n",
       " (41, 'KER_CALLSYNC_CONDVAR_WAIT/82'),\n",
       " (42, 'INT_EXIT0x00000029'),\n",
       " (43, 'KER_CALLMSG_WRITEV/17'),\n",
       " (44, 'KER_CALLMSG_READV/16'),\n",
       " (45, 'KER_EXITCONNECT_ATTACH/39'),\n",
       " (46, 'KER_EXITCONNECT_DETACH/40'),\n",
       " (47, 'KER_EXITTIMER_TIMEOUT/75'),\n",
       " (48, 'COMMREC_MESSAGE'),\n",
       " (49, 'PROCESSPROCCREATE_NAME'),\n",
       " (50, 'INT_EXIT0x0000002d'),\n",
       " (51, 'KER_EXITMSG_SENDVNC/12'),\n",
       " (52, 'USREVENTEVENT-1'),\n",
       " (53, 'THREADTHREPLY'),\n",
       " (54, 'KER_EXITMSG_DELIVER_EVENT/21'),\n",
       " (55, 'THREADTHRECEIVE'),\n",
       " (56, 'KER_CALLCONNECT_FLAGS/43'),\n",
       " (57, 'KER_EXITMSG_WRITEV/17'),\n",
       " (58, 'INT_ENTR0x00000049'),\n",
       " (59, 'INT_ENTR0x0000002d'),\n",
       " (60, 'KER_EXITSYNC_CONDVAR_SIG/83'),\n",
       " (61, 'INT_HANDLER_EXIT0x00000029'),\n",
       " (62, 'INT_HANDLER_ENTR0x00000049'),\n",
       " (63, 'KER_CALLMSG_REPLYV/15'),\n",
       " (64, 'KER_CALLMSG_INFO/19'),\n",
       " (65, 'INT_EXIT0x0000002e'),\n",
       " (66, 'KER_EXITCONNECT_CLIENT_INFO/42'),\n",
       " (67, 'KER_EXITCONNECT_FLAGS/43'),\n",
       " (68, 'THREADTHRUNNING'),\n",
       " (69, 'INT_HANDLER_EXIT0x00000044'),\n",
       " (70, 'INT_HANDLER_EXIT0x0000002e'),\n",
       " (71, 'COMMMSG_ERROR'),\n",
       " (72, 'KER_EXITMSG_READV/16'),\n",
       " (73, 'KER_EXITMSG_ERROR/13'),\n",
       " (74, 'COMMSND_MESSAGE'),\n",
       " (75, 'INT_ENTR0x0000002e'),\n",
       " (76, 'THREADTHCREATE'),\n",
       " (77, 'KER_CALLCONNECT_ATTACH/39'),\n",
       " (78, 'THREADTHJOIN'),\n",
       " (79, 'KER_EXITMSG_RECEIVEV/14'),\n",
       " (80, 'THREADTHSEND'),\n",
       " (81, 'KER_EXITSIGNAL_WAITINFO/32'),\n",
       " (82, 'INT_HANDLER_EXIT0x0000002d')}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(zip(cc0['numKey'], cc0['key'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
